# -*- coding: utf-8 -*-
"""TP1LaboDatos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_Z2b90OFj42H-xYj9j1bILRbLbBzmaXo

#Limpieza de datos/partición de (algunas) tablas

##Carga de modulos y dataframes
"""


import pandas as pd
import re 
from unidecode import unidecode
padron = './TablasOriginales/padron-de-operadores-organicos-certificados.csv'
salario = './TablasOriginales/w_median_depto_priv_clae2.csv'
loccensales = './TablasOriginales/localidades-censales.csv'
dicdepto = './TablasOriginales/diccionario_cod_depto.csv'
dicclase = './TablasOriginales/diccionario_clae2.csv'

df1 = pd.read_csv(padron,encoding = 'windows-1258')
df2 = pd.read_csv(salario)
df3 = pd.read_csv(loccensales)
df4 = pd.read_csv(dicdepto)
df5 = pd.read_csv(dicclase)

#%%
"""##Funciones auxiliares"""

def crear_y_añadir_fila(df,fila_old,col,valor):
    df.loc[len(df)] = df.loc[fila_old,:]
    df.at[len(df)-1, col] = valor

def atomizarFila(df,col,fila,string):
    valores_atomicos = df.loc[fila, col].split(string)
    for valor in valores_atomicos:
        crear_y_añadir_fila(df, fila,col, valor)
        #df.loc[len(df)] = df.loc[fila,:]
        #df.at[len(df)-1, col] = valor
    #borramos la fila original    
    df.drop([fila],inplace=True)
    df.reset_index(drop=True, inplace=True)

def atomizarColumna(df,col,string):
    for i in range(len(df)):
        atomizarFila(df,col,0,string)


def quitar_parentesis(string):
    #Quita todo lo que esta entre parentesis
    regex = r"\([^()]*\)"
    res = re.sub(regex, "", string)
    return res

def reemplazar(string,cadena,reemplazo):
    return string.replace(cadena,reemplazo)

def sacar_espacios_en_extremos(string):
    return string.strip()

def cuantos_nan(df):
    nan_cant = df.isna().sum()
    nan_porcentaje = (nan_cant / len(df)) * 100
    res = pd.concat([nan_cant, nan_porcentaje], axis=1, keys=['Recuento de NaN', 'Porcentaje de NaN'])
    res['Porcentaje de NaN'] = res['Porcentaje de NaN'].round(2).astype(str) + '%'
    res.index = df.columns
    print(res)

def extraer_pronombres(texto):
    # Expresión regular para encontrar pronombres
    patron = r'\b(para|de|con)\b'

    # Remover los pronombres del texto
    texto_sin_pronombres = re.sub(patron, '', texto, flags=re.IGNORECASE)
    
    # Retornar el texto sin pronombres
    return texto_sin_pronombres
    
def quitar_acentos(palabra):
    return unidecode(palabra)

#%%

# DROPS DE LOS DATAFRAMES POR SER CONSIDERADOS COLUMNAS IRRELEVANTES O REDUNDANTES

df1 = df1.drop(['pais','pais_id','localidad'],axis=1)

df3 = df3.drop(60,axis=0).reset_index(drop=True)

#%%

# RENOMBRAMIENTO DE COLUMNAS, PONER EN MAYUSCULA STRINGS, QUITAR ACENTOS DE LOS STRINGS

sin_definir="INDEFINIDO" # para los NaNs

df1['departamento'] = df1['departamento'].str.upper()
df1['departamento'] = df1['departamento'].apply(quitar_acentos)

df2.rename(columns={'id_provincia_indec': 'provincia_id'}, inplace=True)

df3 = df3.rename(columns ={'provincia_nombre':'provincia'})
df3 = df3.rename(columns ={'departamento_nombre':'departamento'})
df3 = df3.rename(columns ={'municipio_nombre':'municipio'})
df3['departamento'] = df3['departamento'].str.upper()
df3['provincia'] = df3['provincia'].str.upper()
df3['nombre'] = df3['nombre'].str.upper()
df3.loc[df3.funcion.isna(),"funcion"]='SIN FUNCIÓN'
df3.loc[df3.municipio.isna(),"municipio"]=sin_definir
df3.loc[df3.municipio_id.isna(),"municipio_id"]=-99
df3.loc[df3.departamento_id.isna(),"departamento_id"]=-99
df3['departamento'] = df3['departamento'].apply(quitar_acentos)
df3['nombre'] = df3['nombre'].apply(quitar_acentos)

df4  = df4.rename(columns ={'codigo_departamento_indec': 'departamento_id'})
df4 = df4.rename(columns ={'nombre_departamento_indec':'departamento'})
df4  = df4.rename(columns ={'id_provincia_indec': 'provincia_id'})
df4 = df4.rename(columns ={'nombre_provincia_indec':'provincia'})
df4.loc[df4.provincia=="Tierra Del Fuego","provincia"]="TIERRA DEL FUEGO"
df4.loc[df4.provincia=="CABA","provincia"]="CIUDAD AUTONOMA BUENOS AIRES"
df4.loc[df4.departamento=="CABA","departamento"]="CIUDAD AUTONOMA BUENOS AIRES"
df4['departamento'] = df4['departamento'].str.upper()
df4['departamento'] = df4['departamento'].apply(quitar_acentos)
df4['provincia'] = df4['provincia'].str.upper()
df4['provincia'] = df4['provincia'].apply(quitar_acentos)

#%%
""" 
df3: Listado de las localidades censales según la base de datos censales del INDEC

Como la consigna del tp nos indica:
"Esta fuente permite asociar a la fuente primaria “Padrón de Operadores Orgánicos
Certificados” con los datos de departamento. Lamentablemente la fuente primaria,
en su campo departamento parece mezclar datos de departamento y ciudad, entre
otras cosas. Esa fuente también tiene inconvenientes en cuanto al formato y
escritura de los nombres (por ejemplo, no parecen contar con tildes, etc.). Deberán
hacer lo necesario para curar y vincular los datos."

Por lo cual debemos vincular ambos dataframe por medio de los nombres de departamento 
e incluir en el df1 los departamento_id correspondientes a cada departamento que aparecen en df3.
"""

#manejamos tuplas con nans y valores sin definir
df3.loc[df3.funcion.isna(),"funcion"]='SIN FUNCIÓN'
df3.loc[df3.municipio.isna(),"municipio"]=sin_definir
df3.loc[df3.municipio_id.isna(),"municipio_id"]=-99
df3.loc[df3.departamento_id.isna(),"departamento_id"]=-99


df3_x = df3.loc[:,['departamento_id','departamento','funcion','nombre','provincia']]

dpto_y_provincia3 = df3.loc[:,['departamento_id','departamento','provincia']].drop_duplicates()

id_departamento = df3.loc[:,['departamento_id']].drop_duplicates()

#PARTIMOS PROVINCIA
df3_provincia = df3[['provincia_id','provincia']].drop_duplicates().reset_index(drop =True)
#correccion para que se asemeje a df4
df3_provincia=df3_provincia.sort_values(by=['provincia_id']) 
df3_dict = df3.drop('provincia',axis=1)

#PARTIMOS MUNICIPIO
df3_municipio = df3[['municipio_id', 'municipio']].drop_duplicates().reset_index(drop=True)
df3_dict = df3.drop('municipio',axis=1)

#PARTIMOS DEPARTAMENTO
df3_departamento = df3[['departamento_id', 'departamento']].drop_duplicates().reset_index(drop=True)
df3_dict = df3.drop('departamento',axis=1)

#PARTIMOS LOCALIDAD
df3_localidad = df3[['id', 'nombre','funcion','centroide_lat','centroide_lon','categoria','fuente']].drop_duplicates().reset_index(drop=True)
df3_dict = df3.drop(labels=['nombre','funcion','centroide_lat','centroide_lon','categoria','fuente'],axis=1)

"""Ahora vinculariamos los df pero nos damos cuenta al hacerlo que hay varios departamentos con el mismo nombre 
pero en distintas provincias. Como ejemplo, tenemos GENERAL ROCA que esta tanto en RÍO NEGRO como en CÓRDOBA.
Por eso también tenemos que tener en cuenta las provincias a la hora de vincular los df
"""

df1['nombre'] = df1['departamento']

df1.loc[df1['departamento'].str.contains('CAPITAL'),'departamento'] = 'CAPITAL'

#Hacemos el merge
df1= df1.merge(df3[['provincia_id','departamento','departamento_id']].drop_duplicates() , on=['provincia_id','departamento'], how='left')
df1= df1.merge(df3[['provincia_id','nombre','departamento_id']].drop_duplicates() , on=['provincia_id','nombre'], how='left',suffixes=['_1','_2'])
df1= df1.merge(df4[['provincia_id','departamento','departamento_id']].drop_duplicates() , on=['provincia_id','departamento'], how='left')
df1['departamento_combinado'] = df1['departamento_id_1'].combine_first(df1['departamento_id_2'])
df1['departamento_id_final'] = df1['departamento_combinado'].combine_first(df1['departamento_id'])

df1 = df1.drop(['nombre','departamento_id_1','departamento_id_2','departamento_id','departamento_combinado'],axis=1)

#Por último ponemos los id al lado de los departamentos
df1 = df1.rename(columns ={'departamento_id_final':'departamento_id'})
df1.insert(2,'departamento_id',df1.pop('departamento_id'))

"""En total df1_corregido tiene 173 NaNs. Si bien todavia quedan esa cantidad de NaNs, originalmente el df1 no tenia IDs de 
departamentos, y ahora tiene 960 filas que si tienen id de departamento.
Esto es verificable con el siguiente comando.
"""

print('Cantidad de NaNs en la columna departamento_id del df1(Padron):', len(df1.loc[df1.departamento_id.isna(),'departamento_id']))

df1 = df1.dropna(subset=['departamento_id'])

#%%
"""##df1:padron

###Tratamiento de **nans** en columna rubro y producto
"""

#En columna rubro y productos vemos los casos particulares
#Veamos si para un producto."CAMPO INCULTO" aplica un valor en especifico para 
#la columna rubro
#Filtramos nans con mascara para evitar mensaje de error:
mask = ~df1.rubro.isna()
df1_rubro_productos_sinNan = df1.loc[df1.productos.str.contains("INCULTO") & mask,["productos","rubro"]]
#Vemos que INCULTO refiere al rubro AGRICULTURA, redefinimos los nan
df1_producto_inculto_conNan = df1.loc[df1.rubro.isna(),["rubro","productos"]]
df1.at[853, 'rubro'] = sin_definir
df1.at[908, 'rubro'] = sin_definir
df1.at[908, 'productos'] = sin_definir
#luego aquellas las que tanto en productos y rubro tengo nan:
mask = df1.rubro.isna() & df1.productos.isna()
df1.loc[mask, ['rubro', 'productos']] = [sin_definir for col in ['rubro', 'productos']]
#fila 879 tiene mas de un producto, a definir mas adelante
df1.loc[879,'rubro'] = sin_definir
#Hay registros con error de tipo: agicultura
df1.loc[df1.rubro == "AGICULTURA","rubro"] = "AGRICULTURA"
#Hay campos con el valor "SIN DEFINIR",, los cambiamos a "INDEFINIDO"
df1.loc[df1.rubro == "SIN DEFINIR","rubro"] = sin_definir
#Aquellas filas en donde contienen puntos. En algunas 
#funcionan como separadores, en otras no aportan nada
terminan_en_punto = df1.rubro.str.endswith('.')
df1.loc[terminan_en_punto,'rubro'] = df1.loc[terminan_en_punto,'rubro'].str.replace(".", "")
#Veo cuantas siguen con puntos como separadores:2,mas adelante los separamos
f = df1.rubro.str.contains("\.")
aux=df1.loc[f,"rubro"]

#Verificamos si siguen habiendo nans
df1.rubro.isna().sum() #0
df1.productos.isna().sum() #0

#%%
"""### Columna producto

Vemos los valores con parentesis
"""

prod_con_par = df1.loc[df1.productos.str.contains("\("),"productos"].unique()
#hay 1 valor con "HORTICULTURA: (RAIZ, HOJAS, FRUTOS) - FRUTALES: (CAROZO, PEPITA, CITRI ..."
con_comas_en_parentesis = df1.productos.str.contains("RAIZ, HOJAS, FRUTOS")
df1.loc[con_comas_en_parentesis,:]

#Lo modificamos manualmente para que rubro contemple a FRUTICULTURA, y productos no tenga parentesis
crear_y_añadir_fila(df1,124,"rubro","HORTICULTURA")
#nos falta modificar su columna productos a esta fila creada
df1.at[len(df1)-1, "productos"] = "RAIZ,HOJAS,FRUTOS"

crear_y_añadir_fila(df1,124,"rubro","FRUTICULTURA")
#nos falta midificar su columna productos a esta fila creada
df1.at[len(df1)-1, "productos"] = "CAROZO,PEPITA,CITRICOS"
#Borramos la fila 124
df1.drop([124],inplace=True)
df1.reset_index(drop=True, inplace=True)

"""A partir de aqui es seguro separar por comas:
Para las filas restantes que contienen parentesis se decidio que son irrelevantes, procedemos a quitar los parentesis excepto para unas pocas en particular que contienen "(CARNE Y LANA)"
"""

#hay 5 valores con "(CARNE Y LANA)"
con_carne_lana = df1.productos.str.contains("CARNE Y LANA")
df1.loc[con_carne_lana,:]

"""Se decide redefinir el atributo productos a "CARNE BOVINA,CARNE OVINA,LANA OVINA"
"""

df1.loc[con_carne_lana,"productos"] = "CARNE BOVINA,CARNE OVINA,LANA"

"""Separamos el atributo productos por coma, ademas sacamos lo que está entre parentesis"""

col = "productos"
df1.productos = df1.productos.apply(quitar_parentesis)
#Spliteamos por comas
atomizarColumna(df1,col,',')
#verificamos si siguen habiendo parentesis
df1.loc[df1.productos.str.contains("\("),"productos"] #0

"""vemos que hay distintos tipos de lana. Ademas para no confundir tenemos en cuenta que "AVELLANA" contiene a "LANA"
"""

df1.loc[df1.productos.str.contains("LANA") &  ~df1.productos.str.contains("AVELLANA"),["productos","rubro"]]

"""Se decide que lana corresponde al rubro procesamiento textil
y los distintos tipos de lanas se unifican en un solo producto: "lana". Excepto 3 en donde sus valores son "TOPS DE LANA" o "BLOUSSE" que quedan en sus respectivos rubros
"""

contienen_lana = df1.productos.str.contains("LANA") &  ~df1.productos.str.contains("AVELLANA") & ~df1.productos.str.contains("BLOUSSE") & ~df1.productos.str.contains("TOPS DE LANA")
df1.loc[contienen_lana,["rubro","productos"]] = ["PROCESAMIENTO TEXTIL","LANA"]
#verifico
df1.loc[contienen_lana,["rubro","productos"]]

#Spliteamos por ; - + ?
atomizarColumna(df1,col,';')
atomizarColumna(df1,col,'-')
atomizarColumna(df1,col,'+')
atomizarColumna(df1,col,'?')

"""Quitamos el caracter "." si lo hubiera"""

df1.productos = df1.productos.apply(reemplazar,args=(".",""))

con_campo_monte_o_pasturas = df1.productos.str.contains("CAMPO") | df1.productos.str.contains("MONTE") | df1.productos.str.contains("PASTURAS")
df1.loc[con_campo_monte_o_pasturas,["rubro","productos"]]

#Definimos el producto como "INCULTO" y rubro "AGRICULTURA"
df1.loc[con_campo_monte_o_pasturas,"productos"] = "INCULTO"
df1.loc[con_campo_monte_o_pasturas,'rubro'] = "AGRICULTURA"

#Algunos registros se cambian manualmente, pues si atomizamos por " y " daran problemas de calidad
con_y = df1.productos.str.contains(" Y ")
ver_registros= df1.loc[con_y,["rubro","productos"]]
ver_registros
df1.loc[2775,["rubro","productos"]] = ["ELABORACION","PULPA DE MANZANA Y JUGO DE MANZANA Y MANZANA DESHIDRATADA"]
df1.loc[3200,["rubro","productos"]] = ["PROCESAMIENTO","CEREALES Y OLEAGINOSAS"]
df1.loc[2880,"productos"] = "JUGO DE LIMON Y ACEITE DE LIMON"
df1.loc[3254,["rubro","productos"]] = ["ALMACENAMIENTO Y FRIO","JUGO CONCENTRADO DE PERA Y PURE DE PERA"]
df1.loc[2781,["rubro","productos"]] = ["ALMACENAMIENTO Y FRIO","JUGO CONCENTRADO DE PERA Y JUGO CONCENTRADO DE MANZANA"]
df1.loc[2246,["rubro","productos"]] = ["FRUTICULTURA-HORTICULTURA","FRUTAS Y HORTICULTURA"]
df1.loc[2219,"rubro"] = "FRUTICULTURA-HORTICULTURA"
df1.loc[3186,["rubro","productos"]] = ["VENTAS","MANI"]
df1.loc[3165,["rubro","productos"]] = ["VENTAS","CEREALES Y OLEAGINOSAS"]
df1.loc[1576,"productos"] = "CEREALES Y OLEAGINOSAS"
df1.loc[2768,["rubro","productos"]] = ["ELABORACION","JUGO CONCENTRADO DE PERA Y JUGO CONCENTRADO DE MANZANA"]
df1.loc[2737,["rubro","productos"]] = ["ELABORACION","JUGO CONCENTRADO DE PERA Y JUGO CONCENTRADO DE MANZANA"]
df1.loc[2782,"rubro"] = "FRUTICULTURA"
df1.loc[2786,"rubro"] = "FRUTICULTURA"
df1.loc[2221,"rubro"] = "APICULTURA"
df1.loc[2878,"rubro"] = "APICULTURA"
df1.loc[2339,"rubro"] = "APICULTURA"
df1.loc[3166,"rubro"] = "APICULTURA"
df1.loc[3276,"rubro"] = "APICULTURA"

#Atomizamos por " Y " y ademas sacamos los espacios en blanco en los extremos
atomizarColumna(df1,col,' Y ')
df1.productos = df1.productos.apply(sacar_espacios_en_extremos)

#%%
"""###Columna rubro"""

col = "rubro"
df1.loc[df1.rubro.str.contains("INDEFINIDO"),["rubro","categoria_desc","productos"]]

#Hay casos en donde esta el rubro elaboracion, pero al separar por comas se rompe. Lo corregimos manualmente
df1.loc[df1.rubro.str.contains("ACEITE ESCENCIAL Y PULPA DE CITRICOS"),["rubro","productos"]]

df1.loc[df1.rubro.str.contains("ACEITE ESCENCIAL Y PULPA DE CITRICOS"),"rubro"] = "ELABORACION"

#Veamos para separar por comas
df1.loc[df1.rubro.str.contains(","),["rubro","productos"]]

col = "rubro"
#no hay casos particulares que arreglar
atomizarColumna(df1,col,',')

#Veamos para separar por punto y coma
df1.loc[df1.rubro.str.contains(";"),["rubro","productos"]]

#No hay casos particulares, separamos:
atomizarColumna(df1,"rubro",';')

#Veamos para separar por guiones
df1.loc[df1.rubro.str.contains("-"),["rubro","productos"]]

#No hay casos particulares, separamos:
atomizarColumna(df1,"rubro",'-')

#Veamos para separar por barras
df1.loc[df1.rubro.str.contains("/"),["rubro","productos"]]

#No hay casos particulares, separamos:
atomizarColumna(df1,"rubro",'/')

#Luego de separar por barra, surgieron otra vez errrores de tipo
df1.loc[df1.rubro == "AGICULTURA","rubro"] = "AGRICULTURA"

#Veamos si hay puntos
df1.loc[df1.rubro.str.contains("\."),"rubro"]
#Actuan como separador:
atomizarColumna(df1,"rubro",'\.')

#Es posible que tengamos problemas al separar por " Y ". La tarea no es trivial.
df1.loc[df1.rubro.str.contains(" Y "),["rubro","productos"]]

#Caso en donde contiene la palabra "PROCESAMIENTO"
df1.loc[df1.rubro.str.contains(" Y ") & df1.rubro.str.contains("PROCESAMIENTO"),["rubro","productos"]].rubro.value_counts()

#Hay un solo caso particular: "PROCESAMIENTO DE TE Y MOLINO YERBA MATE". Los demas solo pueden reemplazarse por la palabra "PROCESAMIENTO"
df1.loc[df1.rubro.str.contains("PROCESAMIENTO FRUTALES Y HORTALIZAS") |
        df1.rubro.str.contains("PROCESAMIENTO CEREALES Y OLEAGINOSAS") |
        df1.rubro.str.contains("PROCESAMIENTO DE CEREALES Y OLEAGINOSAS") |
        df1.rubro.str.contains("PROCESAMIENTO DE MANI Y SOJA")
        ,"rubro"] = "PROCESAMIENTO"

#Veamos mas casos
df1.loc[df1.rubro.str.contains(" Y ") ,["rubro","productos"]].rubro.value_counts()

df1.loc[df1.rubro.str.contains("ACOPIO Y ACONDICIONAMIENTO DE GRANOS") ,"rubro",] = "ACOPIO-ACONDICIONAMIENTO"
df1.loc[df1.rubro.str.contains("FRACCIONAMIENTO Y DEPOSITO DE HIERBAS AROMATICAS Y MEDICINALES") ,"rubro",] = "FRACCIONAMIENTO-DEPOSITO"
df1.loc[df1.rubro.str.contains("ELABORACION DE  JUGOS CONCENTRADOS Y FABRICA DE ACEITES ESENCIALES") ,"rubro",] = "ELABORACION"
df1.loc[df1.rubro.str.contains("EMPAQUE Y FRIGORIFICO DE FRUTAS NO CITRICAS") ,"rubro",] = "EMPAQUE-FRIGORIFICO"
df1.loc[df1.rubro.str.contains("EMPAQUE Y FRIGORIFICO FRUTAS NO CITRICAS ") ,"rubro",] = "EMPAQUE-FRIGORIFICO"
df1.loc[df1.rubro.str.contains("ELABORACION DE JUGO CONCENTRADO DE MANZANA Y PERA") ,"rubro",] = "ELABORACION"
df1.loc[df1.rubro.str.contains("MOLINO Y FRACCIONAMIENTO DE TE") ,"rubro",] = "MOLINO-FRACCIONAMIENTO"
df1.loc[df1.rubro.str.contains("ELABORACION Y EXTRACCION DE ACEITE") ,"rubro",] = "ELABORACION-EXTRACCION"
df1.loc[df1.rubro.str.contains("BODEGA VITIVINICOLA Y ELABORACION DE  VINAGRE") ,"rubro",] = "BODEGA-ELABORACION"
df1.loc[df1.rubro.str.contains("EMPAQUE DE HORTALIZAS Y FRUTAS NO CITRICAS") ,"rubro",] = "EMPAQUE"
df1.loc[df1.rubro.str.contains("ELABORACION DE DULCES Y FRUTAS EN ALMIBAR") ,"rubro",] = "ELABORACION"
df1.loc[df1.rubro.str.contains("PROCESAMIENTO DE TE Y MOLINO YERBA MATE") ,"rubro",] = "PROCESAMIENTO-MOLINO"
df1.loc[df1.rubro.str.contains("ELABORACION DE MANZANA Y PERA DEHIDRATADA") ,"rubro",] = "ELABORACION"
df1.loc[df1.rubro.str.contains("ALMACENAMIENTO Y FRIO PARA FRUTAS NO CITRICAS") ,"rubro",] = "ALMACENAMIENTO-FRIO"
df1.loc[df1.rubro.str.contains("EXTRACCION DE ACEITE Y ELABORACION DE ACEITUNAS Y OTROS") ,"rubro",] = "EXTRACCION-ELABORACION"
df1.loc[df1.rubro.str.contains("PROCESADO Y ENVASADO DE HORTALIZAS") ,"rubro",] = "PROCESADO-ENVASADO"
df1.loc[df1.rubro.str.contains("ELABORACION DE JUGOS Y BODEGA VITIVINICOLA") ,"rubro",] = "ELABORACION-BODEGA"
df1.loc[df1.rubro.str.contains("FRACCIONAMIENTO Y EMPAQUE DE ARROZ") ,"rubro",] = "FRACCIONAMIENTO-EMPAQUE"
df1.loc[df1.rubro.str.contains("FRIGORIFICOS Y EMPAQUE PARA  FRUTAS") ,"rubro",] = "FRIGORIFICOS-EMPAQUE"

#Definimos el rubro "APICULTURA" y productos "MIEL" en 5 casos:
df1.loc[df1.rubro.str.contains("EXTRACCION Y FRACCIONAMIENTO DE MIEL"),["rubro","productos"]]

df1.loc[df1.rubro.str.contains("EXTRACCION Y FRACCIONAMIENTO DE MIEL"),["rubro","productos"]] = ["APICULTURA","MIEL"]

#Solo falta separar por " Y ", "-". Finalmente quitar espacios en blanco extremos
atomizarColumna(df1,"rubro",' Y ')
atomizarColumna(df1,"rubro",'-')
df1.rubro = df1.rubro.apply(sacar_espacios_en_extremos)

#%%
"""##df2:salarios"""

#Como saber cuantos registros de la columna 'w_median' son inferiores a 0

df2_salario_negativo = df2.loc[df2['w_median'] < 0] 


#Y para saber cuanto representan esa cantidad respecto del total simplemente calculamos

len(df2_salario_negativo)/len(df2)*100

#Luego para ubicar los valores NaN en la tabla

NaN_filas = df2[df2.isna().any(axis=1)] # Con esto sabemos cuantas filas tienen al menos 1 NaN
NaN_columnas = df2.columns[df2.isna().any()].tolist() # Con esto sabemos que columnas tienen NaN

# Y ahora podemos fijarnos si los NaN aparecen simultaneamente en ambas columnas o si se dividen apareciendo a veces
# en una y a veces en la otra.

dptoNaN = df2['codigo_departamento_indec'].isna() # Retorna 9156
provNaN = df2['provincia_id'].isna() # Retorna 9156

# Pero con esto no nos alcanza asi que por último chequeamos si cada vez que aparece False o True en dptoNaN 
# se corresponde con los False o True de provNaN. Eso daria una serie de Pandas llena de valores True. Y si el sum()
# (que solo cuenta los True) es igual a la len del dataframe original entonces cada vez que aparece NaN en una aparece
# en la otra.

(dptoNaN == provNaN).sum() == len(df2)  # Esto da True.

df2_sinNaN=df2.dropna() #Armamos otro dataframe sin los NaNs. El df2 original se puede preservar
#por si se quiere hacer un análisis exclusivamente de los salarios y el sector productivo del cual provienen.


#%%
"""## Df4: Diccionario de Departamentos

Partimos en sub-dataframes: """

"""Partimos departamento"""

df4_departamento = df4[['departamento_id', 'departamento']].drop_duplicates().reset_index(drop=True)

"""Partimos provincia """

#correcciones para que df4 sea igual a df3
df4_provincia = df4[['provincia_id','provincia']].drop_duplicates().reset_index(drop =True)

"""Armamos el diccionario de DF4"""

# df4_dict es la versión normalizada de df4 que se conecta mediante la PK con df4_departamento y df4_provincia
df4_dict = df4.drop('departamento',axis=1)
df4_dict = df4_dict.drop('provincia',axis=1)

"""##df5:clases"""

# EL df5 tiene un valor NaN cuando 'clae2' es igual a 999. Esto es debido a que el valor 'OTROS' no tiene asignada una
# letra. Por lo que decidimos asignarle la Z.

df5.loc[85,'letra'] = 'Z'

# PARTIENDO EL DATAFRAME 5

# PARTIMOS CLAE2_DESC

df5_clae2 = df5[['clae2', 'clae2_desc']].drop_duplicates().reset_index(drop=True)

# PARTIMOS LETRA_DESC

df5_letra = df5[['letra', 'letra_desc']].drop_duplicates().reset_index(drop=True)

# df5_dict es la versión normalizada de df5 que se conecta mediante la PK con df5_clae2 y df5_letra
df5_dict = df5.drop('clae2_desc',axis=1)
df5_dict = df5_dict.drop('letra_desc',axis=1)

""" es dificil normalizar df5_clae2 ya que las descripciones estan pensadas como string y no para separarse en valores atomizados.
# NORMALIZAMOS df5_clae2

atomizarColumna(df5_clae2,'clae2_desc', ', ')
atomizarColumna(df5_clae2,'clae2_desc',' y ')
"""

# NORMALIZAMOS df5_letra

# Para ello hace falta renombrar gran parte de las descripciones ya que se pensaron para estar como un string
# pero nosotros queremos atomizar cada atributo para que esten en 1FN en vez de pensarlos como un string.

df5_letra = df5_letra.replace({'EXPLOTACION DE MINAS Y CANTERAS' : 'EXPLOTACIÓN DE MINAS Y EXPLOTACION DE CANTERAS',
                               ' SUMINISTRO DE ELECTRICIDAD, GAS, VAPOR Y AIRE ACONDICIONADO' : 'SUMINISTRO DE ELECTRICIDAD,SUMINISTRO DE GAS, SUMINISTRO DE VAPOR, SUMINISTRO DE AIRE ACONDICIONADO',
                            ' SUMINISTRO DE AGUA; CLOACAS; GESTIÓN DE RESIDUOS Y RECUPERACIÓN DE MATERIALES Y SANEAMIENTO PUBLICO':'SUMINISTRO DE AGUA, CLOACAS, GESTION DE RESIDUOS, RECUPERACIÓN DE MATERIALES, SANEAMIENTO PUBLICO',
                        	' COMERCIO AL POR MAYOR Y AL POR MENOR; REPARACIÓN DE VEHÍCULOS AUTOMOTORES Y MOTOCICLETAS' :'COMERCIO AL POR MAYOR, COMERCIO AL POR MENOR, REPARACION DE VEHICULOS AUTOMOTORES, REPARACION DE MOTOCICLETAS',
                        	' SERVICIO DE TRANSPORTE Y ALMACENAMIENTO':'SERVICIO DE TRANSPORTE, SERVICIO DE ALMACENAMIENTO',
                        	' SERVICIOS PROFESIONALES, CIENTÍFICOS Y TÉCNICOS': 'SERVICIOS PROFESIONALES, SERVICIOS CIENTIFICOS, SERVICIOS TECNICOS',
                        	' SERVICIOS  ARTÍSTICOS, CULTURALES, DEPORTIVOS  Y DE ESPARCIMIENTO': 'SERVICIOS ARTISTICOS, SERVICIOS CULTURALES, SERVICIOS DEPORTIVOS, SERVICIOS DE ESPARCIMIENTO',
                            })

# Una vez renombrado todo a mano porque hacer una función tardaria demasiado. Podemos atomizar

atomizarColumna(df5_letra,'letra_desc', ', ')
atomizarColumna(df5_letra,'letra_desc',' y ')
df5_letra.letra_desc = df5_letra.letra_desc.apply(sacar_espacios_en_extremos) # esta función elimina los espacios al principio y final de las palabras gracias a la función strip

#%%

"""##Exportamos todos los csv a la carpeta TablasLimpias

"""

df3.to_csv('./TablasLimpias/df3.csv', index=False)
df1.to_csv('./TablasLimpias/df1.csv', index=False)
df4_departamento.to_csv('./TablasLimpias/departamentos_df4.csv', index=False)
df4_provincia.to_csv('./TablasLimpias/provincias_df4.csv', index=False)
df4_dict.to_csv('./TablasLimpias/df4.csv', index=False)
df5_letra.to_csv('./TablasLimpias/categorias.csv', index=False)
df5_dict.to_csv('./TablasLimpias/df5.csv', index=False)
